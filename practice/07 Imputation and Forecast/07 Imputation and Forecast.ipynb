{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40b60845-d818-442d-94f8-6b933141500a",
   "metadata": {},
   "source": [
    "## Анализ и прогнозирование временных рядов методами искусственного интеллекта"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0724ed1a-025b-4c1a-bf3a-ab13be8a52d1",
   "metadata": {},
   "source": [
    "### **Практическая работа 7. Востановление пропусков и прогноз значений временного ряда.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa9cac9-dc42-48c3-a387-b268e3f2ca9b",
   "metadata": {},
   "source": [
    "#### **7.1 Аналитечкие методы востановления временного ряда**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd2600-bd98-4624-9923-b8f555bff401",
   "metadata": {},
   "source": [
    "##### *Краткое описание*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d81988-ec79-4adb-bfa4-e5deba5eb104",
   "metadata": {},
   "source": [
    "В данном пункте практической работы вам предстоит познакомиться с базовыми, аналитическими методами восстановления временных рядов.\n",
    "Для выполнения данного пункта из каждой группы методов, представленных в ***табл. 7.1*** вам необходимо выбрать по одному методу восстановления ряда. При работе с первой группой, вам необходимо самостоятельно реализовать выбранный метод.  \n",
    "\n",
    "**Табл. 7.1** - Группы аналитических методов восстановления.\n",
    "№|Название группы|Модели и методы|\n",
    "--|----|----|\n",
    "1|Заполнение существующими значениями ряда|Средним, медианной, Hot-Deck|\n",
    "2|Заполнение на основе близки значений|[Интерполяция](https://scikit-learn.org/stable/auto_examples/linear_model/plot_polynomial_interpolation.html),  [KNNi](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html)|\n",
    "3|На основе матричных разложений|[CD-Rec](#Fixme:Дат ссылку), [SVD](https://pypi.org/project/fancyimpute/)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55867193-e858-4d3a-9595-babb03077b8c",
   "metadata": {},
   "source": [
    "##### 7.1.1 Загрузка и подготовка данных\n",
    "В данной работе вы будете использовать следующие наборы данных:\n",
    "1. фывфыв\n",
    "2. фывфв"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc4e423d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in /Users/dmitrijmakotin/Library/Python/3.9/lib/python/site-packages (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8658fac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (58.0.4)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-69.0.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: wheel in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (0.37.0)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.42.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Using cached setuptools-69.0.2-py3-none-any.whl (819 kB)\n",
      "Using cached wheel-0.42.0-py3-none-any.whl (65 kB)\n",
      "Installing collected packages: wheel, setuptools\n",
      "Successfully installed setuptools-69.0.2 wheel-0.42.0\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22b9b90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fancyimpute\n",
      "  Using cached fancyimpute-0.7.0.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting knnimpute>=0.1.0 (from fancyimpute)\n",
      "  Using cached knnimpute-0.1.0.tar.gz (8.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.2 in /Users/dmitrijmakotin/Library/Python/3.9/lib/python/site-packages (from fancyimpute) (1.3.0)\n",
      "Collecting cvxpy (from fancyimpute)\n",
      "  Using cached cvxpy-1.4.1-cp39-cp39-macosx_10_9_universal2.whl.metadata (8.8 kB)\n",
      "Collecting cvxopt (from fancyimpute)\n",
      "  Using cached cvxopt-1.3.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (1.3 kB)\n",
      "Collecting pytest (from fancyimpute)\n",
      "  Using cached pytest-7.4.3-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting nose (from fancyimpute)\n",
      "  Using cached nose-1.3.7-py3-none-any.whl (154 kB)\n",
      "Requirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.10 in /Users/dmitrijmakotin/Library/Python/3.9/lib/python/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/dmitrijmakotin/Library/Python/3.9/lib/python/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/dmitrijmakotin/Library/Python/3.9/lib/python/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/dmitrijmakotin/Library/Python/3.9/lib/python/site-packages (from scikit-learn>=0.24.2->fancyimpute) (3.2.0)\n",
      "Collecting osqp>=0.6.2 (from cvxpy->fancyimpute)\n",
      "  Using cached osqp-0.6.3.tar.gz (228 kB)\n",
      "  Installing build dependencies ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[113 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Collecting oldest-supported-numpy\n",
      "  \u001b[31m   \u001b[0m   Using cached oldest_supported_numpy-2023.10.25-py3-none-any.whl.metadata (9.8 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting setuptools>=40.8.0\n",
      "  \u001b[31m   \u001b[0m   Using cached setuptools-69.0.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting wheel\n",
      "  \u001b[31m   \u001b[0m   Using cached wheel-0.42.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting setuptools_scm>=6.2\n",
      "  \u001b[31m   \u001b[0m   Using cached setuptools_scm-8.0.4-py3-none-any.whl.metadata (6.4 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting qdldl\n",
      "  \u001b[31m   \u001b[0m   Using cached qdldl-0.1.7.post0.tar.gz (70 kB)\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: started\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   Getting requirements to build wheel: started\n",
      "  \u001b[31m   \u001b[0m   Getting requirements to build wheel: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   Installing backend dependencies: started\n",
      "  \u001b[31m   \u001b[0m   Installing backend dependencies: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): started\n",
      "  \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m Collecting numpy==1.21.0 (from oldest-supported-numpy)\n",
      "  \u001b[31m   \u001b[0m   Using cached numpy-1.21.0-cp39-cp39-macosx_11_0_arm64.whl (12.1 MB)\n",
      "  \u001b[31m   \u001b[0m Collecting packaging>=20 (from setuptools_scm>=6.2)\n",
      "  \u001b[31m   \u001b[0m   Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting typing-extensions (from setuptools_scm>=6.2)\n",
      "  \u001b[31m   \u001b[0m   Using cached typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting tomli>=1 (from setuptools_scm>=6.2)\n",
      "  \u001b[31m   \u001b[0m   Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting scipy>=0.13.2 (from qdldl)\n",
      "  \u001b[31m   \u001b[0m   Using cached scipy-1.11.4-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "  \u001b[31m   \u001b[0m INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "  \u001b[31m   \u001b[0m   Using cached scipy-1.11.3-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "  \u001b[31m   \u001b[0m   Using cached scipy-1.11.2-cp39-cp39-macosx_12_0_arm64.whl.metadata (54 kB)\n",
      "  \u001b[31m   \u001b[0m   Using cached scipy-1.11.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (54 kB)\n",
      "  \u001b[31m   \u001b[0m   Using cached scipy-1.10.1-cp39-cp39-macosx_12_0_arm64.whl (28.9 MB)\n",
      "  \u001b[31m   \u001b[0m Using cached oldest_supported_numpy-2023.10.25-py3-none-any.whl (4.9 kB)\n",
      "  \u001b[31m   \u001b[0m Using cached setuptools-69.0.2-py3-none-any.whl (819 kB)\n",
      "  \u001b[31m   \u001b[0m Using cached wheel-0.42.0-py3-none-any.whl (65 kB)\n",
      "  \u001b[31m   \u001b[0m Using cached setuptools_scm-8.0.4-py3-none-any.whl (42 kB)\n",
      "  \u001b[31m   \u001b[0m Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "  \u001b[31m   \u001b[0m Using cached typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "  \u001b[31m   \u001b[0m Building wheels for collected packages: qdldl\n",
      "  \u001b[31m   \u001b[0m   Building wheel for qdldl (pyproject.toml): started\n",
      "  \u001b[31m   \u001b[0m   Building wheel for qdldl (pyproject.toml): finished with status 'error'\n",
      "  \u001b[31m   \u001b[0m   \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for qdldl \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m╰─>\u001b[0m \u001b[31m[59 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/Users/dmitrijmakotin/Library/Python/3.9/bin/cmake\", line 5, in <module>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     from cmake import cmake\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m ModuleNotFoundError: No module named 'cmake'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/Users/dmitrijmakotin/Library/Python/3.9/lib/python/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/Users/dmitrijmakotin/Library/Python/3.9/lib/python/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/Users/dmitrijmakotin/Library/Python/3.9/lib/python/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 251, in build_wheel\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     return _build_backend().build_wheel(wheel_directory, config_settings,\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 404, in build_wheel\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     return self._build_with_temp_dir(\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 389, in _build_with_temp_dir\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 311, in run_setup\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"<string>\", line 113, in <module>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/__init__.py\", line 103, in setup\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/dist.py\", line 963, in run_command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/normal/lib/python3.9/site-packages/wheel/bdist_wheel.py\", line 368, in run\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     self.run_command(\"build\")\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/dist.py\", line 963, in run_command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/_distutils/command/build.py\", line 131, in run\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/dist.py\", line 963, in run_command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/command/build_ext.py\", line 88, in run\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     _build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/d2/vhpr87y51v5c3w9tbzxpmkgh0000gn/T/pip-build-env-08d702rw/overlay/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py\", line 345, in run\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     self.build_extensions()\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"<string>\", line 81, in build_extensions\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py\", line 424, in check_output\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py\", line 528, in run\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     raise CalledProcessError(retcode, process.args,\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m subprocess.CalledProcessError: Command '['cmake', '--version']' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m  ERROR: Failed building wheel for qdldl\u001b[0m\u001b[31m\n",
      "  \u001b[31m   \u001b[0m \u001b[0mFailed to build qdldl\n",
      "  \u001b[31m   \u001b[0m \u001b[31mERROR: Could not build wheels for qdldl, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "  \u001b[31m   \u001b[0m \u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install fancyimpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5228adbe-931c-40d5-85ca-b6cf3e798e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5cbe3c-dbc1-496b-b08a-6f25cbcaa9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('')/'madrid.txt'\n",
    "madrid = np.loadtxt(path_data)[:,0]\n",
    "print(madrid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d82b22a-6570-4727-ac3b-441701e5da72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =  plt.subplots(figsize=(14,4),ncols=1,nrows=1)\n",
    "plt.plot(madrid[:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6192bc7d-20a3-4191-b4c1-1ea0f1f47e72",
   "metadata": {},
   "source": [
    "Самостоятельно реализуйте функцию, принимающую на вход многомерный временной ряд и возвращающий:\n",
    "1. Все подпоследовательности временного ряда, в которых некоторые значения временного ряда были заменены nan значениями.\n",
    "2. Индексы пропущенных значейни\n",
    "   \n",
    "Процен пппроущенных значений должен регулироваться тедельным параметром.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb62221-3a1f-4e40-a993-1393a0a378c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import random\n",
    "\n",
    "def add_nan(x, percent = 0.25):\n",
    "    x_nan = copy.deepcopy(x)\n",
    "    nan_len = x.shape[0] * percent\n",
    "    nan_counter = 0\n",
    "\n",
    "    for i in range(x_nan.shape[0]):\n",
    "        if nan_counter <= nan_len and random.randint(0, 1):\n",
    "            x_nan[i] = np.nan\n",
    "            nan_counter += 1\n",
    "\n",
    "    return x_nan, np.isnan(x_nan)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a4546-a3e6-47cb-815d-f6b1f2b3ccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid_with_nan, index = add_nan(madrid)\n",
    "fig, ax =  plt.subplots(figsize=(14,6),ncols=1,nrows=2)\n",
    "ax[0].plot(madrid[:1000])\n",
    "ax[1].plot(madrid_with_nan[:1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d601f-09e7-4466-a03e-cb7312960c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovery = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de8afc-398f-45d5-a0c5-7706e1d36ae5",
   "metadata": {},
   "source": [
    "##### 7.1.2 Заполнение существующими значениями ряда\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389b4436-6935-4e23-9678-ec981227ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid_mean = madrid_with_nan.copy()\n",
    "madrid_mean[index] = np.nanmean(madrid_mean)\n",
    "recovery['mean'] = madrid_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f21b8b4-79fd-470b-9ea8-8cc73c6af827",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =  plt.subplots(figsize=(14,6),ncols=1,nrows=2)\n",
    "ax[0].plot(madrid[:1000])\n",
    "ax[1].plot(madrid_mean[:1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f9924e-e3da-410c-9ab3-12dd68a80a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid_median = madrid_with_nan.copy()\n",
    "madrid_median[index] = np.nanmedian(madrid_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5998a52-445c-4d9f-8b10-e4d60ba04520",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovery['median'] = madrid_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2563d8f1-91b7-4edf-bcb5-95664e1bf29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#madrid_with_nan, index = add_nan(madrid)\n",
    "fig, ax =  plt.subplots(figsize=(14,6),ncols=1,nrows=2)\n",
    "ax[0].plot(madrid[:1000])\n",
    "ax[1].plot(madrid_median[:1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db34ca5-71ae-4f4a-87f1-ae07b84e2008",
   "metadata": {},
   "source": [
    "Самостоятельно реализуйте один метод из первой группы ***табл. 7\n",
    ".1*** и проведите востановление данных, сохратив результаты востановления."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7536caa9-f109-423d-b322-5e1fc7de4479",
   "metadata": {},
   "source": [
    "##### 7.1.3 Заполнение на основе близких значений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf5210-9aa1-42a7-8d2d-053827519a15",
   "metadata": {},
   "source": [
    "Используя документацию одного из методов востановления второй группы ***табл. .1*** и проведите востановление данных, сохратив результаты востановления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32fdec9-3495-4e1d-b46c-cd7ceb7868dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae8f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid_with_nan, index = add_nan(madrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf8f46-ec51-4d2f-8440-a77163b8ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(a, window, intersection=False):\n",
    "    # result = torch.zeros(size=(a.shape[0],a.shape[1]))\n",
    "    returns = []\n",
    "    if intersection:  \n",
    "        for i in range(0, a.shape[0]-window):\n",
    "            returns.append(a[i:i + window])\n",
    "    else:    \n",
    "        for i in range(0, a.shape[0],window):\n",
    "            returns.append(a[i:i + window])\n",
    "    return np.stack(returns)\n",
    "madrid_slice = rolling_window(madrid_with_nan, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f091ca-5d2a-4cfd-9085-25a275adf634",
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid_slice = rolling_window(madrid_with_nan, 100)\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=10)\n",
    "\n",
    "madrid_knn_imputer = imputer.fit_transform(madrid_slice)\n",
    "madrid_knn_imputer = madrid_knn_imputer.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a551af",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovery['knn_imputer'] = madrid_knn_imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe97f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =  plt.subplots(figsize=(14,3),ncols=1,nrows=1)\n",
    "ax.plot(madrid[:1000])\n",
    "ax.plot(madrid_knn_imputer[:1000], alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0671a4-d220-4b89-9ed6-d138533f29c5",
   "metadata": {},
   "source": [
    "##### 7.1.4 Заполнение на матричных преобразований"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dafb1d-9e30-4e3f-961e-d0142105c69f",
   "metadata": {},
   "source": [
    "Используя документацию одного из методов востановления третей группы ***табл. 7.1*** и проведите востановление данных, сохратив результаты востановления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2343644",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip --version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ab8a9-5b15-4330-b99b-057eea5677fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fancyimpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e42a2-e6b0-4696-afa3-13f5f16b933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fancyimpute import IterativeSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66483cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = IterativeSVD(rank=2)\n",
    "madrid_iterative_svd = madrid_slice.copy()\n",
    "madrid_iterative_svd = solver.fit_transform(madrid_iterative_svd)\n",
    "madrid_iterative_svd = madrid_iterative_svd.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527ae1ca-e0a0-4396-afb7-b78f6f2380ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd637509-371c-4721-9f47-658ea5495e67",
   "metadata": {},
   "source": [
    "##### 7.1.5 Сравнение результатов востановление.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c02aed0-816c-43ff-839c-a9ef78406288",
   "metadata": {},
   "source": [
    "Используя следующие библиотеки(список библиотек) отдельно для каждой группы методов постройте методов основные метрики оценки качества постановления.\n",
    "На основе метрик отберите лучшие методы постановления метрик и выберите лучшую группу методов. Для лучших методов из каждой группы постройте графики сравнения реальных и восстановленных данных. Объясните результаты и сделайте вывод.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f7c239-00f9-4786-9886-78ba3516045a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d55179cc-3d0e-40f6-9c5d-8d2f33bb9ec6",
   "metadata": {},
   "source": [
    "*Вывод*:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0cdf4a-9e4e-4e21-b1a3-2b623728cd85",
   "metadata": {},
   "source": [
    "#### **7.2 Нейросетевые методы востановления временного ряда**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd59bb79-d695-4192-85ab-26aba286330c",
   "metadata": {},
   "source": [
    "##### *Краткое описание*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458c45a6-5c90-4701-a36f-04a2a3d66582",
   "metadata": {},
   "source": [
    "В данном пункте практической работы вам предстоит познакомиться с некоторыми нейросетевыми методами восстановления временных рядов.\n",
    "Для выполнения данного пункта вам предстоит самостоятельно реализовать структуру нейросетевой, модели основанной на GRU нейронах и сравнить ее с другими нейросетевыми методами восстановления При сравнение с 3 группой из **табл.7. 2** вам необходимо выбрать **один** метод восстановлени.. Основные блоки обработки данных будут реализованы с использованиме Pytorch. Вам не запрещается использовать для реализации Keras.\n",
    "\n",
    "**т*ал7 5.2** - Нейросетевые методы восстановления.\n",
    "№|Название группы|Модели и методы|\n",
    "--|-------------|----|\n",
    "1|Линейные нейроны|[Pytorch](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)|\n",
    " 2eкрркуретные нейронны|[Pytorch](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html)|\n",
    "3|Сложные структуры|[SAITS, BRITS, M-RNN](https://github.com/WenjieDu/PyPOTS)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd10c199-f920-4fe8-99bc-949320a44f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovery_nn = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748aee14-dd66-48a7-8c4d-371c86f4e683",
   "metadata": {},
   "source": [
    "##### 7.2.1 Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476fd8d-dec7-441a-a977-d9b2a68d90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('Dataset')/'madrid.txt'\n",
    "madrid = np.loadtxt(path_data)[:,:]\n",
    "print(madrid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b7adc2-ff78-4b6e-a2a2-2e2cccbd19ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid_with_nan, index = add_nan(madrid, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb637456-ae37-488f-8168-6cc20780e148",
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid_with_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42232bd8-b8f1-4fe8-909c-adc42073537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "madrid_normal_with_nan = scaler.fit_transform(madrid_with_nan)\n",
    "rolling_madrid = rolling_window(madrid_normal_with_nan, 100, True)\n",
    "train, test = train_test_split(rolling_madrid,shuffle=False, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0db477-3ac2-4db2-a837-91dabc59851d",
   "metadata": {},
   "source": [
    "##### 7.2.2 Базовая модель востановлениях данных, построенная на нескольких слоях линейных нейроннах \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a038f6-dea9-41b4-ab93-030513fd75c2",
   "metadata": {},
   "source": [
    "Вам необходимо будет самостоятельно реализовать:\n",
    "1. инициализацию nan значений какими либо другими значениями.\n",
    "2. замер времени полного обучения и тестирования модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f862ef-fc85-4f8a-97ca-8d786d8a6f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26ab0e-65f6-467d-98ed-08f9a161aa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, size_subsequent: int,dim = 1, nums_layers = 3, size_layers = 250):\n",
    "        super().__init__()  \n",
    "        \n",
    "        self.size_subsequent = size_subsequent\n",
    "        self.nums_layers = nums_layers*dim\n",
    "        self.dim = dim\n",
    "        self.size_layers = size_layers\n",
    "        \n",
    "        self.start_layers = nn.Sequential(nn.Flatten(),\n",
    "                                          nn.Linear(size_subsequent*dim, self.size_layers),\n",
    "                                          nn.LeakyReLU())\n",
    "        self.model = nn.ModuleList([\n",
    "                                        (nn.Sequential(\n",
    "                                                nn.Linear(self.size_layers, self.size_layers), nn.LeakyReLU()\n",
    "                                            ) \n",
    "                                        )\n",
    "                                    for x in torch.arange(nums_layers)])\n",
    "        self.model = nn.Sequential(*self.model)\n",
    "        \n",
    "        self.output = nn.Sequential(nn.Linear(self.size_layers,size_subsequent*dim),nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.start_layers(x)\n",
    "        \n",
    "        x=self.model(x)\n",
    "        x=self.output(x)\n",
    "        return x.reshape(x.shape[0],self.size_subsequent,self.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f9e96e-2702-4f37-bf3f-52b599d7bdc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f214e69-1a14-495a-b8f5-bb3568a27db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel(size_subsequent=train.shape[1],dim=train.shape[2])\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1.0e-3)\n",
    "loss_func = nn.MSELoss()\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "batch_size = 64\n",
    "percent = 0.25\n",
    "\n",
    "train_loader = DataLoader(train,batch_size=batch_size,shuffle=True)\n",
    "valid_loader = DataLoader(test,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "print(train.shape,test.shape)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f6a7b6-e262-4b7d-8852-4d7fffc9c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8304be01-8fcf-4b91-8f3c-3c0644f0fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "times_model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75486d83-e8e8-456c-b570-d519024d2e68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=model.to(device)\n",
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "start = time.time()\n",
    "for epoch in np.arange(epochs):\n",
    "    train_loss =0\n",
    "    valid_loss =0\n",
    "\n",
    "    for i, x in enumerate(train_loader):\n",
    "        if x.shape[0] == batch_size:\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(device).to(torch.float32)\n",
    "            test_index = np.isnan(x.cpu().numpy())\n",
    "            X = x.clone()\n",
    "            X, nan = add_nan(X,percent)\n",
    "            ###вставте инициализацию нулями nan значений\n",
    "            recovery = model(X)\n",
    "            loss = loss_func(recovery[(nan)&(~test_index)],x[(nan)&(~test_index)])\n",
    "            train_loss += loss.detach().cpu().item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    train_loss/=(i+1)\n",
    "    print('valid')\n",
    "    with torch.no_grad():\n",
    "        for i, x in enumerate(valid_loader):\n",
    "            if x.shape[0] == batch_size:\n",
    "                x = x.to(device).to(torch.float32)\n",
    "                test_index = np.isnan(x.cpu().numpy())\n",
    "                X = x.clone()\n",
    "                X, nan = add_nan(X,percent)\n",
    "                X[torch.isnan(X)]=0.0\n",
    "                recovery = model(X)\n",
    "                loss = loss_func(recovery[(nan)&(~test_index)],x[(nan)&(~test_index)])\n",
    "                valid_loss += loss.detach().cpu().item()\n",
    "    valid_loss/=(i+1)\n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    print(f'epoch:{epoch+1} train:{train_loss}, valid:{valid_loss}')\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79b86ed-986f-4546-8b58-00a26e0715e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_model['linear']=end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21a9cb4-e205-473c-b848-25b7fa17c6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd262f3-c613-4ef8-b924-3b68257afa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_history,label='train')\n",
    "plt.plot(valid_history,label='valid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4d4053-8e7a-414c-8b02-53a9fa90db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rolling_madrid = rolling_window(madrid_normal_with_nan, 100, False)\n",
    "#test = []\n",
    "with torch.no_grad():\n",
    "    for idx, batch in enumerate(test_rolling_madrid):\n",
    "        batch = torch.Tensor(batch).to(device)\n",
    "        nan = torch.isnan(batch)\n",
    "        batch[nan]=0.0\n",
    "        rec = model(batch[None,:])[0].cpu().numpy()\n",
    "        nan = nan.cpu().numpy()\n",
    "        test_rolling_madrid[idx][nan]=rec[nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c75ce4-ec0c-4b46-93cd-5c1070997468",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_madrid_normal = np.vstack(test_rolling_madrid)\n",
    "test_linear = scaler.inverse_transform(test_madrid_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f308e6-7e7a-4988-9a48-b661b538c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovery_nn['linear'] = test_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ff544e-ad5c-4c19-8e11-8acb056d08fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =  plt.subplots(figsize=(14,3),ncols=1,nrows=1)\n",
    "\n",
    "plt.plot(madrid[:1000,0])\n",
    "plt.plot(test_linear[:1000,0],alpha=0.6)\n",
    "print(mean_squared_error(madrid[index].reshape(1,-1),test_linear[index].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058c480b-2404-422f-aa7c-7bcbcbda9575",
   "metadata": {},
   "source": [
    "##### 7.2.3 Реккурентная модель востановлениях данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb451860-6790-44f9-ba91-c7af3aa7662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderGRU(nn.Module):\n",
    "    def __init__(self, size_subsequent: int, dim = 1, latten_size = 100, hidden_size=100):\n",
    "        super().__init__()\n",
    "        self.size_subsequent=size_subsequent\n",
    "        self.dim = dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size=dim,\n",
    "                          hidden_size=self.hidden_size)\n",
    "        \n",
    "        self.latten = nn.Linear(hidden_size*size_subsequent,latten_size)\n",
    "        self.leaky = nn.LeakyReLU()\n",
    "        self.fl = nn.Flatten()\n",
    "    def forward(self, x):\n",
    "        x, _ = self.gru(x)\n",
    "        x = self.leaky(x)\n",
    "        #print(x.shape)\n",
    "        x = self.fl(x)\n",
    "        x = self.latten(x)\n",
    "        return self.leaky(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2076eb1-9626-4566-b62f-9910ef587e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderGRU(nn.Module):\n",
    "    def __init__(self, size_subsequent: int, dim = 1, latten_size = 100, hidden_size=100):\n",
    "        super().__init__()\n",
    "        self.size_subsequent=size_subsequent\n",
    "        self.dim = dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.latten_size=latten_size\n",
    "        self.gru = nn.GRU(input_size=self.hidden_size,\n",
    "                          hidden_size=dim)\n",
    "        self.latten = nn.Linear(latten_size,hidden_size*size_subsequent)\n",
    "        self.leaky = nn.LeakyReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.latten(x)\n",
    "        x = x.view(-1, self.size_subsequent, self.latten_size)\n",
    "        x = self.leaky(x)\n",
    "        x, _ = self.gru(x)\n",
    "        return self.leaky(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef164c2-4536-4d90-ad86-a61b82892bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeAE(nn.Module):\n",
    "    def __init__(self, size_subsequent: int, dim = 1, latten_size = 100, hidden_size=100):\n",
    "        super().__init__()\n",
    "        self.encoder = EncoderGRU(size_subsequent=size_subsequent,\n",
    "                                 dim=dim,\n",
    "                                 latten_size=latten_size,\n",
    "                                 hidden_size=hidden_size) \n",
    "        self.decoder = DecoderGRU(size_subsequent=size_subsequent,\n",
    "                                 dim=dim,\n",
    "                                 latten_size=latten_size,\n",
    "                                 hidden_size=hidden_size) \n",
    "    def forward(self, x):\n",
    "        x=self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec90ed6-487b-4739-a4a0-12005d4f9c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimeAE(size_subsequent=train.shape[1],dim=train.shape[2])\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1.0e-3)\n",
    "loss_func = nn.MSELoss()\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "batch_size = 64\n",
    "percent = 0.25\n",
    "\n",
    "train_loader = DataLoader(train,batch_size=batch_size,shuffle=True)\n",
    "valid_loader = DataLoader(test,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed29eccb-448b-44e6-bdae-d501c079ca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644b1dd-5841-4f66-842b-4e2b0ac549fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=model.to(device)\n",
    "train_history = []\n",
    "valid_history = []\n",
    "start = time.time()\n",
    "for epoch in np.arange(epochs):\n",
    "    train_loss =0\n",
    "    valid_loss =0\n",
    "\n",
    "    for i, x in enumerate(train_loader):\n",
    "        if x.shape[0]==batch_size:\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(device).to(torch.float32)\n",
    "            test_index = np.isnan(x.cpu().numpy())\n",
    "            X = x.clone()\n",
    "            X, nan = add_nan(X,percent)\n",
    "            #\n",
    "            \n",
    "            recovery = model(X)\n",
    "            loss = loss_func(recovery[(nan)&(~test_index)],x[(nan)&(~test_index)])\n",
    "            train_loss += loss.detach().cpu().item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    train_loss/=(i+1)\n",
    "    with torch.no_grad():\n",
    "        for i, x in enumerate(valid_loader):\n",
    "            if x.shape[0]==batch_size:\n",
    "                x = x.to(device).to(torch.float32)\n",
    "                test_index = np.isnan(x.cpu().numpy())\n",
    "                X = x.clone()\n",
    "                X, nan = add_nan(X,percent)\n",
    "                # \n",
    "                \n",
    "                recovery = model(X)\n",
    "                loss = loss_func(recovery[(nan)&(~test_index)],x[(nan)&(~test_index)])\n",
    "                valid_loss += loss.detach().cpu().item()\n",
    "    valid_loss/=(i+1)\n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    print(f'epoch:{epoch+1} train:{train_loss}, valid:{valid_loss}')\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8133f835-4415-461b-a39f-02db669fe834",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_history,label='train')\n",
    "plt.plot(valid_history,label='valid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95aad1-f1ea-4d0e-b06c-9a18fc94a412",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_model['ae']=end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694dc1bb-19ef-43dc-8499-a48c1e21c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rolling_madrid = rolling_window(madrid_normal_with_nan, 100, False)\n",
    "#test = []\n",
    "with torch.no_grad():\n",
    "    for idx, batch in enumerate(test_rolling_madrid):\n",
    "        batch = torch.Tensor(batch).to(device)\n",
    "        nan = torch.isnan(batch)\n",
    "        #\n",
    "        \n",
    "        rec = model(batch[None,:])[0].cpu().numpy()\n",
    "        nan = nan.cpu().numpy()\n",
    "        test_rolling_madrid[idx][nan]=rec[nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c363d9-dab8-4180-8e2c-6437eef35460",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_madrid_normal = np.vstack(test_rolling_madrid)\n",
    "test_ae = scaler.inverse_transform(test_madrid_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d3b9d7-5b76-4d2a-9c7b-fec26a985c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovery_nn['test_ae'] = test_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb9f9ac-afcc-4b9e-8bf2-4778a4b982a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =  plt.subplots(figsize=(14,3),ncols=1,nrows=1)\n",
    "\n",
    "plt.plot(madrid[:1000,0])\n",
    "plt.plot(test_ae[:1000,0],alpha=0.6)\n",
    "print(mean_squared_error(madrid[index].reshape(1,-1),test_ae[index].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9989ac02-3da4-49a2-9c90-d86b8f7ca806",
   "metadata": {},
   "source": [
    "##### 7.2.4 Сложные модели нейросетевого востановлениях данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5261fdf2-637c-4805-9ac9-651998c736ef",
   "metadata": {},
   "source": [
    "Вам необходимо выбрать одну модель из 3 группы таблицы 7.2 и используя документацию произвести восстановления того же ряда. Произведите замер времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed5ade9-577b-4172-8395-c2e01f517387",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypots==0.0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af84ecb6-9d32-40ba-bdd4-820ae3811390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypots.imputation import SAITS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322c9df6-f49b-42ec-83a2-54b80aa947ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= SAITS(n_features=madrid.shape[1],\n",
    "             n_steps=100,\n",
    "             device=device,\n",
    "             d_k=64,\n",
    "             d_v=64,\n",
    "             d_model=128,\n",
    "             d_inner=128,\n",
    "             n_head=4,\n",
    "             n_layers=2,\n",
    "             dropout=0.05,\n",
    "             epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f93dd0-249e-424a-9ac0-62dfce0d5de2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model.fit(train,test)\n",
    "end = time.time()\n",
    "times_model['saits']=end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e9cb2e-461e-45d8-aa93-b62d9c25bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rolling_madrid = rolling_window(madrid_normal_with_nan, 100, False)\n",
    "test_rolling_madrid = model.impute(test_rolling_madrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623d0ab-aca2-485f-82a8-fc059b1f9c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_madrid_normal = np.vstack(test_rolling_madrid)\n",
    "test_saits = scaler.inverse_transform(test_madrid_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a3a1e4-96e7-4af4-bb71-f9005dd73ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovery_nn['saits'] = test_saits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f8a33c-b8c0-4b4e-957c-fea343e864dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =  plt.subplots(figsize=(14,3),ncols=1,nrows=1)\n",
    "\n",
    "plt.plot(madrid[:1000,0])\n",
    "plt.plot(test_saits[:1000,0],alpha=0.6)\n",
    "print(mean_squared_error(madrid[index].reshape(1,-1),test_saits[index].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e88b24f-2c98-4fc1-8d58-3365f4091cbb",
   "metadata": {},
   "source": [
    "##### 7.2.5 Сравнения результатов.\n",
    "Также, как и в пункте 7.1.5 постройте графики сравнения моделей. Дополнительно постройте графики сравнения времени. Сделайте выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27150f18-c69d-45c3-8f1c-73b2d9bcd9d7",
   "metadata": {},
   "source": [
    "#### **7.3 Прогноз временного ряда**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b73dde-c7b2-4674-91ed-01a5d1f1b494",
   "metadata": {},
   "source": [
    "##### *Краткое описание*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da70fd-e22e-4465-808a-1db0b3f125f7",
   "metadata": {},
   "source": [
    "Используя модель и [ARIMA](реализация) произвидите прогноз ряда на следующие колличество точек: 1, 5, 10.\n",
    "Сравните результаты. Постройте графики прогноза и точности прогноза."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdac684d-39fc-4e9a-b625-baa7ff312b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
